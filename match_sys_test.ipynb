{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from service import config\n",
    "config.initialize()\n",
    "\n",
    "from service.MatchSys import MatchSys\n",
    "ms = MatchSys(\n",
    "        name='teat_sys',\n",
    "        ltp_model_path=r'D:\\Code\\MyLongTimeProject\\A\\QQ-Bot-And-Tool\\data\\LtpModel',\n",
    "        database_uri='sqlite:///data/db.sqlite3',\n",
    "        text_vec_model_path=r'D:\\Code\\MyLongTimeProject\\A\\QQ-Bot-And-Tool\\data\\model.pkl'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "map = {}\n",
    "# data = pd.read_excel(r'C:\\Users\\Administrator\\Documents\\GitHub\\QQ-Bot-And-Tool\\data\\FixedReply\\傲娇系二次元bot词库5千词V1.2.xlsx',header=None, sheet_name=0)\n",
    "data = pd.read_excel(r\"D:\\temp\\Downloads\\傲娇系二次元bot词库5千词V1.2 - Test.xlsx\",header=None, sheet_name=0)\n",
    "for index,row in data.iterrows():\n",
    "    if row[0] in map:\n",
    "        map[row[0]].append(row[1])\n",
    "    else:\n",
    "        map[row[0]] = [row[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from service.MatchSys.trainer import QATrainer\n",
    "trainer = QATrainer(ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ms.get_response('你')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in range(ms.message_adapter.snowflake.get_id()):\n",
    "    a.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {}\n",
    "conversation_text = kwargs.get('conversation', 'TRAIN_DATA')\n",
    "statements_to_create = []\n",
    "previous_id = 0\n",
    "next_id = 0\n",
    "kwargs['type_of'] = 'Q'\n",
    "kwargs['persona'] = 'user:*'\n",
    "input_statements = ms.message_adapter.process_list(list(map.keys()),**kwargs)\n",
    "for index,input_statement in enumerate(input_statements):\n",
    "    statements_to_create.append(input_statement)\n",
    "    kwargs['id'] = next_id\n",
    "    kwargs['type_of'] = 'A'\n",
    "    kwargs['persona'] = 'bot:'+ms.name\n",
    "\n",
    "data = ms.docvector_tool.build_tokenzied(statements_to_create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "count = 0\n",
    "for tag in data:\n",
    "    tag.tags[0] = count\n",
    "    temp.append(tag)\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "ms.docvector_tool.model = Doc2Vec(temp,dm=1, window=8, min_count=5, workers=4)\n",
    "ms.docvector_tool.model.train(temp,total_examples=ms.docvector_tool.model.corpus_count,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec\n",
    "import jieba\n",
    "# 加载数据\n",
    "documents = []\n",
    "# 使用count当做每个句子的“标签”，标签和每个句子是一一对应的\n",
    "count = 0\n",
    "for line in list(map.keys()):\n",
    "    documents.append(TaggedDocument(jieba.lcut_for_search(line), [str(line),count]))\n",
    "    count = count + 1\n",
    "# 模型训练\n",
    "model = Doc2Vec(documents, dm=1, window=8, min_count=5, workers=4)\n",
    "model.train(documents,total_examples=model.corpus_count,epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferred_vector = model.infer_vector(doc_words=['热', '死', '我', '了'])\n",
    "sims = model.dv.most_similar([inferred_vector],topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sim in sims:\n",
    "    print(sim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

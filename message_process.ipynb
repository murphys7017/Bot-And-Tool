{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'data': [\n",
    "    {'nickname': 'ÂÖ≥‰ºØÂÖ∞', 'remark': 'ÂÖ≥‰ºØÂÖ∞', 'user_id': 474527445}, \n",
    "    {'nickname': 'üçÅüçÅüçÅ', 'remark': 'üçÅüçÅüçÅ', 'user_id': 577003680}, \n",
    "], 'message': '', 'retcode': 0, 'status': 'ok'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Áî®Êà∑Ê∂àÊÅØËá≥ÊéßÂà∂Âô®DispatcherServlet\n",
    "2.DispatcherServletËøõË°åÂä†Â∑•Â§ÑÁêÜÂêéË∞ÉÁî®Â§ÑÁêÜÂô®Êò†Â∞ÑÂô®HandlerMapping„ÄÇ\n",
    "3.HandlerMappingÊ†πÊçÆÊ∂àÊÅØÊâæÂà∞ÂÖ∑‰ΩìÁöÑÂ§ÑÁêÜÂô®ÔºåÁîüÊàêÂìçÂ∫îÊ∂àÊÅØËøîÂõûÁªôDispatcherServlet„ÄÇ\n",
    "4.DispatcherServletÊ†πÊçÆÂ§ÑÁêÜÂô®HandlerËé∑ÂèñÂ§ÑÁêÜÂô®ÈÄÇÈÖçÂô®HandlerAdapterÊâßË°åHandlerAdapterÂ§ÑÁêÜ‰∏ÄÁ≥ªÂàóÁöÑÊìç‰ΩúÔºåÂ¶ÇÔºöÂèÇÊï∞Â∞ÅË£ÖÔºåÊï∞ÊçÆÊ†ºÂºèËΩ¨Êç¢ÔºåÊï∞ÊçÆÈ™åËØÅÁ≠âÊìç‰Ωú\n",
    "5.ÊâßË°åÂ§ÑÁêÜÂô®Handler(ControllerÔºå‰πüÂè´È°µÈù¢ÊéßÂà∂Âô®)„ÄÇ\n",
    "6.HandlerÊâßË°åÂÆåÊàêËøîÂõûModelAndView\n",
    "7.HandlerAdapterÂ∞ÜHandlerÊâßË°åÁªìÊûúModelAndViewËøîÂõûÂà∞DispatcherServlet\n",
    "8.DispatcherServletÂ∞ÜModelAndView‰º†ÁªôViewResloverËßÜÂõæËß£ÊûêÂô®\n",
    "9.ViewResloverËß£ÊûêÂêéËøîÂõûÂÖ∑‰ΩìView\n",
    "10.DispatcherServletÂØπViewËøõË°åÊ∏≤ÊüìËßÜÂõæÔºàÂç≥Â∞ÜÊ®°ÂûãÊï∞ÊçÆmodelÂ°´ÂÖÖËá≥ËßÜÂõæ‰∏≠Ôºâ„ÄÇ\n",
    "11.DispatcherServletÂìçÂ∫îÁî®Êà∑„ÄÇ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    'post_type': 'message', \n",
    "    'message_type': 'private', \n",
    "    'time': 1694183059, \n",
    "    'self_id': 2762018040, \n",
    "    'sub_type': 'friend', \n",
    "    'target_id': 2762018040, \n",
    "    'message': '‰Ω†Â•Ω', \n",
    "    'raw_message': '‰Ω†Â•Ω', \n",
    "    'font': 0, \n",
    "    'sender': {'age': 0, 'nickname': 'Aki-Polaris', 'sex': 'unknown', 'user_id': 815049548}, \n",
    "    'message_id': -2001115448, \n",
    "    'user_id': 815049548\n",
    "}\n",
    "message_info = {\n",
    "    'post_type': 'message', \n",
    "    'message_type': 'group', \n",
    "    'time': 1694395091, \n",
    "    'self_id': 2762018040, \n",
    "    'sub_type': 'normal', \n",
    "    'anonymous': None, \n",
    "    'message': '[CQ:image,file=138fd15bdabbcfb4c3daa148555fe447.image,subType=1,url=https://gchat.qpic.cn/gchatpic_new/1352402688/830954892-2582910460-138FD15BDABBCFB4C3DAA148555FE447/0?term=255&amp;is_origin=0]', \n",
    "    'message_seq': 81567, \n",
    "    'raw_message': '[CQ:image,file=138fd15bdabbcfb4c3daa148555fe447.image,subType=1,url=https://gchat.qpic.cn/gchatpic_new/1352402688/830954892-2582910460-138FD15BDABBCFB4C3DAA148555FE447/0?term=255&amp;is_origin=0]', \n",
    "    'font': 0, \n",
    "    'group_id': 830954892, \n",
    "    'sender': {'age': 0, 'area': '', 'card': '', 'level': '', 'nickname': 'Á¶ªÂ≤±ÂíåËëõÈ•∞Â∫î‰∏∫', 'role': 'member', 'sex': 'unknown', 'title': '', 'user_id': 1352402688}, \n",
    "    'user_id': 1352402688, \n",
    "    'message_id': -185279243\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltp import LTP\n",
    "ltp = LTP('LTP/small')\n",
    "message = 'ÊòéÂ§©Â§©ÊÄé‰πàÊ†∑ÂëÄ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from service.MatchSys.object_definition import Statement\n",
    "from service.MatchSys.utils import import_module\n",
    "\n",
    "\n",
    "class MessageAdapter(object):\n",
    "    \"\"\"\n",
    "    This is an abstract class that represents the interface\n",
    "    that all message adapters should implement.\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs) -> None:\n",
    "        from service.MatchSys.object_definition import Statement\n",
    "        from ltp import LTP\n",
    "\n",
    "        # ÂàùÂßãÂåñÈ¢ÑÂ§ÑÁêÜÁ®ãÂ∫è\n",
    "        preprocessors = kwargs.get('preprocessors', ['jionlp.clean_text'])\n",
    "        self.preprocessors = []\n",
    "        for preprocessor in preprocessors:\n",
    "            self.preprocessors.append(import_module(preprocessor))\n",
    "        \n",
    "        model_path = kwargs.get('model_path', 'LTP/small')\n",
    "        self.ltp = LTP(model_path)\n",
    "    class AdapterMethodNotImplementedError(NotImplementedError):\n",
    "        \"\"\"\n",
    "        An exception to be raised when an adapter method has not been implemented.\n",
    "        Typically this indicates that the developer is expected to implement the\n",
    "        method in a subclass.\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(self, message='This method must be overridden in a subclass method.'):\n",
    "            \"\"\"\n",
    "            Set the message for the exception.\n",
    "            \"\"\"\n",
    "            super().__init__(message)\n",
    "\n",
    "    def check(self, message):\n",
    "        if message is None or message == '':\n",
    "            raise self.ChatBotException(\n",
    "                'Either a statement object or a \"text\" keyword '\n",
    "                'argument is required. Neither was provided.'\n",
    "            )\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def process(self, message):\n",
    "        # read the message\n",
    "\n",
    "        # Get Text message\n",
    "        input_statement = self.text_process(text=message)\n",
    "\n",
    "        # Add Other Info\n",
    "\n",
    "        # Ëé∑ÂèñStatement\n",
    "        raise self.AdapterMethodNotImplementedError()\n",
    "\n",
    "    def text_process(self, text,**kwargs):\n",
    "        \"\"\"Return Search Text\n",
    "\n",
    "        Args:\n",
    "            text (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: Statement\n",
    "        \"\"\"\n",
    "        # Ê∏ÖÁêÜÊñáÊú¨\n",
    "        for preprocessor in self.preprocessors:\n",
    "            text = preprocessor(text)\n",
    "        kwargs['text'] = text\n",
    "        # ÂàÜËØç\n",
    "        result = self.ltp.pipeline('‰Ω†ËßâÂæóAÊÄé‰πàÊ†∑', tasks = [\"cws\",\"srl\"])\n",
    "        kwargs['search_text'] = result.cws\n",
    "        t = result.srl[0]\n",
    "        for item in result.srl:\n",
    "            if len(t['arguments']) > len(item['arguments']):\n",
    "                t = item\n",
    "        kwargs['intent'] = t\n",
    "\n",
    "        input_statement = Statement(**kwargs)\n",
    "        return input_statement\n",
    "\n",
    "    @property\n",
    "    def class_name(self):\n",
    "        \"\"\"\n",
    "        Return the name of the current logic adapter class.\n",
    "        This is typically used for logging and debugging.\n",
    "        \"\"\"\n",
    "        return str(self.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextMessageAdapter(MessageAdapter):\n",
    "    \"\"\"\n",
    "    This is an abstract class that represents the interface\n",
    "    that all message adapters should implement.\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def process(self, message):\n",
    "        # read the message\n",
    "\n",
    "        # Get Text message\n",
    "        input_statement = self.text_process(text=message)\n",
    "\n",
    "        # Add Other Info\n",
    "\n",
    "        # Ëé∑ÂèñStatement\n",
    "        return input_statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_adapter = TextMessageAdapter(model_path=r'D:\\Code\\MyLongTimeProject\\A\\model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from service.MatchSys.trainers import Trainer\n",
    "from service.MatchSys.utils import print_progress_bar\n",
    "\n",
    "class QATrainer(Trainer):\n",
    "    \"\"\"\n",
    "    Allows a chat bot to be trained using a list of strings\n",
    "    where the list represents a conversation.\n",
    "    \"\"\"\n",
    "\n",
    "    def train(self, conversation, **kwargs):\n",
    "        \"\"\"\n",
    "        {Q:[A1,A2...]}\n",
    "        Train the chat bot based on the provided list of\n",
    "        statements that represents a single conversation.\n",
    "        \"\"\"\n",
    "        source = kwargs.get('source', 'TRAIN_DATA')\n",
    "        conversation_text = kwargs.get('conversation', 'TRAIN_DATA')\n",
    "        statements_to_create = []\n",
    "        for index,Q in enumerate(conversation):\n",
    "            if self.show_training_progress:\n",
    "                print_progress_bar(\n",
    "                    'QA Trainer',\n",
    "                    index + 1, len(conversation)\n",
    "                )\n",
    "    \n",
    "            statement = self.chatbot.message_adapter.process(Q)\n",
    "            statement.next_id=-statement.id\n",
    "            statement.conversation=conversation_text\n",
    "            statement.type_of='Q'\n",
    "            statement.source=source\n",
    "            statement.persona='user'\n",
    "            statements_to_create.append(statement)\n",
    "            for A in conversation[Q]:\n",
    "                statement = self.chatbot.message_adapter.process(A)\n",
    "                statement.previous_id=-statement.id\n",
    "                statement.conversation=conversation_text\n",
    "                statement.type_of='A'\n",
    "                statement.source=source\n",
    "                statement.persona='bot:'+self.chatbot.name\n",
    "                statements_to_create.append(statement)\n",
    "        self.chatbot.storage.create_many(statements_to_create)\n",
    "        self.chatbot.docvector_tool.train(statements_to_create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from service.MatchSys.match_sys import MatchSys\n",
    "\n",
    "\n",
    "matchsys = MatchSys(name='Alice',model_path=r'D:\\Code\\MyLongTimeProject\\A\\model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qatrain = QATrainer(matchsys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "a = pd.read_csv(r'data1.txt',\n",
    "                sep=\"$\",\n",
    "                engine='python'\n",
    "                )\n",
    "a.head(5)\n",
    "a.to_csv(r'data1.csv',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'a':[1,2,3], 'b':[4,5,6], 'c':[7,8]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "('a', [1, 2, 3])\n",
      "1\n",
      "('b', [4, 5, 6])\n",
      "2\n",
      "('c', [7, 8])\n"
     ]
    }
   ],
   "source": [
    "for index,k in enumerate(a.items()):\n",
    "    print(index)\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "map = {}\n",
    "# data = pd.read_excel(r'C:\\Users\\Administrator\\Documents\\GitHub\\QQ-Bot-And-Tool\\data\\FixedReply\\ÂÇ≤Â®áÁ≥ª‰∫åÊ¨°ÂÖÉbotËØçÂ∫ì5ÂçÉËØçV1.2.xlsx',header=None, sheet_name=0)\n",
    "data = pd.read_excel(r\"data\\FixedReply\\Test-1K.xlsx\",header=None, sheet_name=0)\n",
    "for index,row in data.iterrows():\n",
    "    row[0] = str(row[0]).strip()\n",
    "    row[1] = str(row[1]).strip()\n",
    "    if row[0] in map:\n",
    "        map[row[0]].append(row[1])\n",
    "    else:\n",
    "        map[row[0]] = [row[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaissSearch(object):\n",
    "    def __init__(self,**kwargs):\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        self.vector_model = SentenceTransformer('data/text2vec-base-chinese')\n",
    "        self.nlist = 50\n",
    "        self.index_search = None\n",
    "        self.signal_file_size = 10000\n",
    "    def data_process_2_vector(self,**kwargs):\n",
    "        data_list = kwargs.get('data_list',None)\n",
    "        file_list = kwargs.get('file_list',None)\n",
    "        # Âä†ËΩΩÊ®°ÂûãÔºåÂ∞ÜÊï∞ÊçÆËøõË°åÂêëÈáèÂåñÂ§ÑÁêÜ\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        model = SentenceTransformer('data/text2vec-base-chinese')\n",
    "        sentences = data_list\n",
    "        sentence_embeddings = self.vector_model.encode(data_list)\n",
    "        # Â∞ÜÂêëÈáèÂ§ÑÁêÜÁªìÊûúÂ≠òÂÇ®\n",
    "        import numpy as np\n",
    "        import os\n",
    "        save_file = \"data/vec_data.npy\"\n",
    "        np.save(save_file, sentence_embeddings)\n",
    "\n",
    "        file_size = os.path.getsize(save_file)\n",
    "        print(\"%7.3f MB\" % (file_size/1024/1024))\n",
    "    def build_faiss_index(self):\n",
    "        # Âä†ËΩΩÈ¢ÑÂ§ÑÁêÜÊï∞ÊçÆ\n",
    "        import numpy as np\n",
    "        sentences = list(map.keys())\n",
    "        sentence_embeddings = np.load(\"data/vec_data.npy\")\n",
    "        print(\"ËΩΩÂÖ•ÂêëÈáèÊï∞ÊçÆÂÆåÊØïÔºåÊï∞ÊçÆÈáè\", len(sentence_embeddings))\n",
    "\n",
    "        # ‰ΩøÁî®ÊûÑÂª∫ÂêëÈáèÊó∂ÁöÑÊ®°ÂûãÊù•ÊûÑÂª∫ÂêëÈáèÁ¥¢Âºï\n",
    "        import faiss\n",
    "        dimension = sentence_embeddings.shape[1]\n",
    "        quantizer = faiss.IndexFlatL2(dimension)\n",
    "        self.index_search = faiss.IndexIVFFlat(quantizer, dimension, self.nlist)\n",
    "        index.train(sentence_embeddings)\n",
    "        index.add(sentence_embeddings)\n",
    "        print(\"Âª∫Á´ãÂêëÈáèÁ¥¢ÂºïÂÆåÊØïÔºåÊï∞ÊçÆÈáè\", index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ËΩΩÂÖ•ÂêëÈáèÊï∞ÊçÆÂÆåÊØïÔºåÊï∞ÊçÆÈáè 976\n",
      "Âª∫Á´ãÂêëÈáèÁ¥¢ÂºïÂÆåÊØïÔºåÊï∞ÊçÆÈáè 976\n",
      "ËΩΩÂÖ•Ê®°ÂûãÂÆåÊØï\n"
     ]
    }
   ],
   "source": [
    "# Âä†ËΩΩÈ¢ÑÂ§ÑÁêÜÊï∞ÊçÆ\n",
    "import numpy as np\n",
    "sentences = list(map.keys())\n",
    "sentence_embeddings = np.load(\"data/vec_data.npy\")\n",
    "print(\"ËΩΩÂÖ•ÂêëÈáèÊï∞ÊçÆÂÆåÊØïÔºåÊï∞ÊçÆÈáè\", len(sentence_embeddings))\n",
    "\n",
    "# ‰ΩøÁî®ÊûÑÂª∫ÂêëÈáèÊó∂ÁöÑÊ®°ÂûãÊù•ÊûÑÂª∫ÂêëÈáèÁ¥¢Âºï\n",
    "import faiss\n",
    "dimension = sentence_embeddings.shape[1]\n",
    "quantizer = faiss.IndexFlatL2(dimension)\n",
    "nlist = 50\n",
    "index = faiss.IndexIVFFlat(quantizer, dimension, nlist)\n",
    "index.train(sentence_embeddings)\n",
    "index.add(sentence_embeddings)\n",
    "print(\"Âª∫Á´ãÂêëÈáèÁ¥¢ÂºïÂÆåÊØïÔºåÊï∞ÊçÆÈáè\", index.ntotal)\n",
    "\n",
    "# Â∞ùËØïËøõË°åÊü•ËØ¢\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('data/text2vec-base-chinese')\n",
    "print(\"ËΩΩÂÖ•Ê®°ÂûãÂÆåÊØï\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "topK = 10\n",
    "search = model.encode([\"Â•ΩÁ¥ØÂïä\"])\n",
    "D, I = index.search(search, topK)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.9502930e-10 4.5865227e+01 8.8828560e+01 1.0693193e+02 1.2101427e+02\n",
      "  1.5374112e+02 3.4294498e+02 3.7847754e+02 3.4028235e+38 3.4028235e+38]]\n",
      "[[ 33 632 589 605 531 330  76 825  -1  -1]]\n"
     ]
    }
   ],
   "source": [
    "print(D)\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Â•ΩÁ¥ØÂïä\n",
      "Â•ΩÁ¥ØÂì¶\n",
      "Â•ΩÁ¥Ø\n",
      "ÊàëÂ•ΩÁ¥Ø\n",
      "ÊàëÁ¥Ø‰∫Ü\n",
      "Á¥ØÂêó\n",
      "ÊàëËÉå‰Ω†\n",
      "ÊàëË¶ÅËÜùÊûï\n"
     ]
    }
   ],
   "source": [
    "for i in I[0]:\n",
    "    if i != -1:\n",
    "        ret = list(map.keys())[i]\n",
    "        print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Êï∞ÊçÆÁ±ªÂûã <class 'numpy.ndarray'>\n",
      "Êï∞ÁªÑÂÖÉÁ¥†Êï∞ÊçÆÁ±ªÂûãÔºö float32\n",
      "Êï∞ÁªÑÂÖÉÁ¥†ÊÄªÊï∞Ôºö 749568\n",
      "Êï∞ÁªÑÂΩ¢Áä∂Ôºö (976, 768)\n",
      "Êï∞ÁªÑÁöÑÁª¥Â∫¶Êï∞ÁõÆ 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Êï∞ÊçÆÁ±ªÂûã\",type(sentence_embeddings))           #ÊâìÂç∞Êï∞ÁªÑÊï∞ÊçÆÁ±ªÂûã  \n",
    "print(\"Êï∞ÁªÑÂÖÉÁ¥†Êï∞ÊçÆÁ±ªÂûãÔºö\",sentence_embeddings.dtype) #ÊâìÂç∞Êï∞ÁªÑÂÖÉÁ¥†Êï∞ÊçÆÁ±ªÂûã  \n",
    "print(\"Êï∞ÁªÑÂÖÉÁ¥†ÊÄªÊï∞Ôºö\",sentence_embeddings.size)      #ÊâìÂç∞Êï∞ÁªÑÂ∞∫ÂØ∏ÔºåÂç≥Êï∞ÁªÑÂÖÉÁ¥†ÊÄªÊï∞  \n",
    "print(\"Êï∞ÁªÑÂΩ¢Áä∂Ôºö\",sentence_embeddings.shape)         #ÊâìÂç∞Êï∞ÁªÑÂΩ¢Áä∂  \n",
    "print(\"Êï∞ÁªÑÁöÑÁª¥Â∫¶Êï∞ÁõÆ\",sentence_embeddings.ndim)      #ÊâìÂç∞Êï∞ÁªÑÁöÑÁª¥Â∫¶Êï∞ÁõÆ  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.2970518 , -0.25346562, -0.23536594, ..., -0.6353451 ,\n",
       "         0.36731493,  0.02351565],\n",
       "       [-0.54003495, -0.79583836,  0.38487688, ..., -0.4618318 ,\n",
       "        -1.2059765 , -0.12932391],\n",
       "       [ 0.32315907,  0.10518757, -0.52833754, ...,  0.43228775,\n",
       "        -0.9100478 , -0.8505187 ],\n",
       "       ...,\n",
       "       [-0.2751668 ,  0.65258443,  0.08361594, ...,  0.22980374,\n",
       "        -1.2248287 , -0.50112844],\n",
       "       [ 0.7900612 , -0.63520163,  0.25002787, ..., -0.710253  ,\n",
       "        -0.94551253, -0.39789113],\n",
       "       [ 0.5351167 ,  0.34678018,  1.0117722 , ..., -0.03430998,\n",
       "         0.1018568 ,  0.01111399]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'data': [\n",
    "    {'nickname': 'å…³ä¼¯å…°', 'remark': 'å…³ä¼¯å…°', 'user_id': 474527445}, \n",
    "    {'nickname': 'ğŸğŸğŸ', 'remark': 'ğŸğŸğŸ', 'user_id': 577003680}, \n",
    "], 'message': '', 'retcode': 0, 'status': 'ok'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.ç”¨æˆ·æ¶ˆæ¯è‡³æ§åˆ¶å™¨DispatcherServlet\n",
    "2.DispatcherServletè¿›è¡ŒåŠ å·¥å¤„ç†åè°ƒç”¨å¤„ç†å™¨æ˜ å°„å™¨HandlerMappingã€‚\n",
    "3.HandlerMappingæ ¹æ®æ¶ˆæ¯æ‰¾åˆ°å…·ä½“çš„å¤„ç†å™¨ï¼Œç”Ÿæˆå“åº”æ¶ˆæ¯è¿”å›ç»™DispatcherServletã€‚\n",
    "4.DispatcherServletæ ¹æ®å¤„ç†å™¨Handlerè·å–å¤„ç†å™¨é€‚é…å™¨HandlerAdapteræ‰§è¡ŒHandlerAdapterå¤„ç†ä¸€ç³»åˆ—çš„æ“ä½œï¼Œå¦‚ï¼šå‚æ•°å°è£…ï¼Œæ•°æ®æ ¼å¼è½¬æ¢ï¼Œæ•°æ®éªŒè¯ç­‰æ“ä½œ\n",
    "5.æ‰§è¡Œå¤„ç†å™¨Handler(Controllerï¼Œä¹Ÿå«é¡µé¢æ§åˆ¶å™¨)ã€‚\n",
    "6.Handleræ‰§è¡Œå®Œæˆè¿”å›ModelAndView\n",
    "7.HandlerAdapterå°†Handleræ‰§è¡Œç»“æœModelAndViewè¿”å›åˆ°DispatcherServlet\n",
    "8.DispatcherServletå°†ModelAndViewä¼ ç»™ViewResloverè§†å›¾è§£æå™¨\n",
    "9.ViewResloverè§£æåè¿”å›å…·ä½“View\n",
    "10.DispatcherServletå¯¹Viewè¿›è¡Œæ¸²æŸ“è§†å›¾ï¼ˆå³å°†æ¨¡å‹æ•°æ®modelå¡«å……è‡³è§†å›¾ä¸­ï¼‰ã€‚\n",
    "11.DispatcherServletå“åº”ç”¨æˆ·ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    'post_type': 'message', \n",
    "    'message_type': 'private', \n",
    "    'time': 1694183059, \n",
    "    'self_id': 2762018040, \n",
    "    'sub_type': 'friend', \n",
    "    'target_id': 2762018040, \n",
    "    'message': 'ä½ å¥½', \n",
    "    'raw_message': 'ä½ å¥½', \n",
    "    'font': 0, \n",
    "    'sender': {'age': 0, 'nickname': 'Aki-Polaris', 'sex': 'unknown', 'user_id': 815049548}, \n",
    "    'message_id': -2001115448, \n",
    "    'user_id': 815049548\n",
    "}\n",
    "message_info = {\n",
    "    'post_type': 'message', \n",
    "    'message_type': 'group', \n",
    "    'time': 1694395091, \n",
    "    'self_id': 2762018040, \n",
    "    'sub_type': 'normal', \n",
    "    'anonymous': None, \n",
    "    'message': '[CQ:image,file=138fd15bdabbcfb4c3daa148555fe447.image,subType=1,url=https://gchat.qpic.cn/gchatpic_new/1352402688/830954892-2582910460-138FD15BDABBCFB4C3DAA148555FE447/0?term=255&amp;is_origin=0]', \n",
    "    'message_seq': 81567, \n",
    "    'raw_message': '[CQ:image,file=138fd15bdabbcfb4c3daa148555fe447.image,subType=1,url=https://gchat.qpic.cn/gchatpic_new/1352402688/830954892-2582910460-138FD15BDABBCFB4C3DAA148555FE447/0?term=255&amp;is_origin=0]', \n",
    "    'font': 0, \n",
    "    'group_id': 830954892, \n",
    "    'sender': {'age': 0, 'area': '', 'card': '', 'level': '', 'nickname': 'ç¦»å²±å’Œè‘›é¥°åº”ä¸º', 'role': 'member', 'sex': 'unknown', 'title': '', 'user_id': 1352402688}, \n",
    "    'user_id': 1352402688, \n",
    "    'message_id': -185279243\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltp import LTP\n",
    "ltp = LTP('LTP/small')\n",
    "message = 'æ˜å¤©å¤©æ€ä¹ˆæ ·å‘€'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from service.MatchSys.object_definition import Statement\n",
    "from service.MatchSys.utils import import_module\n",
    "\n",
    "\n",
    "class MessageAdapter(object):\n",
    "    \"\"\"\n",
    "    This is an abstract class that represents the interface\n",
    "    that all message adapters should implement.\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs) -> None:\n",
    "        from service.MatchSys.object_definition import Statement\n",
    "        from ltp import LTP\n",
    "\n",
    "        # åˆå§‹åŒ–é¢„å¤„ç†ç¨‹åº\n",
    "        preprocessors = kwargs.get('preprocessors', ['jionlp.clean_text'])\n",
    "        self.preprocessors = []\n",
    "        for preprocessor in preprocessors:\n",
    "            self.preprocessors.append(import_module(preprocessor))\n",
    "        \n",
    "        model_path = kwargs.get('model_path', 'LTP/small')\n",
    "        self.ltp = LTP(model_path)\n",
    "    class AdapterMethodNotImplementedError(NotImplementedError):\n",
    "        \"\"\"\n",
    "        An exception to be raised when an adapter method has not been implemented.\n",
    "        Typically this indicates that the developer is expected to implement the\n",
    "        method in a subclass.\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(self, message='This method must be overridden in a subclass method.'):\n",
    "            \"\"\"\n",
    "            Set the message for the exception.\n",
    "            \"\"\"\n",
    "            super().__init__(message)\n",
    "\n",
    "    def check(self, message):\n",
    "        if message is None or message == '':\n",
    "            raise self.ChatBotException(\n",
    "                'Either a statement object or a \"text\" keyword '\n",
    "                'argument is required. Neither was provided.'\n",
    "            )\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def process(self, message):\n",
    "        # read the message\n",
    "\n",
    "        # Get Text message\n",
    "        input_statement = self.text_process(text=message)\n",
    "\n",
    "        # Add Other Info\n",
    "\n",
    "        # è·å–Statement\n",
    "        raise self.AdapterMethodNotImplementedError()\n",
    "\n",
    "    def text_process(self, text,**kwargs):\n",
    "        \"\"\"Return Search Text\n",
    "\n",
    "        Args:\n",
    "            text (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: Statement\n",
    "        \"\"\"\n",
    "        # æ¸…ç†æ–‡æœ¬\n",
    "        for preprocessor in self.preprocessors:\n",
    "            text = preprocessor(text)\n",
    "        kwargs['text'] = text\n",
    "        # åˆ†è¯\n",
    "        result = self.ltp.pipeline('ä½ è§‰å¾—Aæ€ä¹ˆæ ·', tasks = [\"cws\",\"srl\"])\n",
    "        kwargs['search_text'] = result.cws\n",
    "        t = result.srl[0]\n",
    "        for item in result.srl:\n",
    "            if len(t['arguments']) > len(item['arguments']):\n",
    "                t = item\n",
    "        kwargs['intent'] = t\n",
    "\n",
    "        input_statement = Statement(**kwargs)\n",
    "        return input_statement\n",
    "\n",
    "    @property\n",
    "    def class_name(self):\n",
    "        \"\"\"\n",
    "        Return the name of the current logic adapter class.\n",
    "        This is typically used for logging and debugging.\n",
    "        \"\"\"\n",
    "        return str(self.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextMessageAdapter(MessageAdapter):\n",
    "    \"\"\"\n",
    "    This is an abstract class that represents the interface\n",
    "    that all message adapters should implement.\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def process(self, message):\n",
    "        # read the message\n",
    "\n",
    "        # Get Text message\n",
    "        input_statement = self.text_process(text=message)\n",
    "\n",
    "        # Add Other Info\n",
    "\n",
    "        # è·å–Statement\n",
    "        return input_statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_adapter = TextMessageAdapter(model_path=r'D:\\Code\\MyLongTimeProject\\A\\model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from service.MatchSys.trainers import Trainer\n",
    "from service.MatchSys.utils import print_progress_bar\n",
    "\n",
    "class QATrainer(Trainer):\n",
    "    \"\"\"\n",
    "    Allows a chat bot to be trained using a list of strings\n",
    "    where the list represents a conversation.\n",
    "    \"\"\"\n",
    "\n",
    "    def train(self, conversation, **kwargs):\n",
    "        \"\"\"\n",
    "        {Q:[A1,A2...]}\n",
    "        Train the chat bot based on the provided list of\n",
    "        statements that represents a single conversation.\n",
    "        \"\"\"\n",
    "        source = kwargs.get('source', 'TRAIN_DATA')\n",
    "        conversation_text = kwargs.get('conversation', 'TRAIN_DATA')\n",
    "        statements_to_create = []\n",
    "        for index,Q in enumerate(conversation):\n",
    "            if self.show_training_progress:\n",
    "                print_progress_bar(\n",
    "                    'QA Trainer',\n",
    "                    index + 1, len(conversation)\n",
    "                )\n",
    "    \n",
    "            statement = self.chatbot.message_adapter.process(Q)\n",
    "            statement.next_id=-statement.id\n",
    "            statement.conversation=conversation_text\n",
    "            statement.type_of='Q'\n",
    "            statement.source=source\n",
    "            statement.persona='user'\n",
    "            statements_to_create.append(statement)\n",
    "            for A in conversation[Q]:\n",
    "                statement = self.chatbot.message_adapter.process(A)\n",
    "                statement.previous_id=-statement.id\n",
    "                statement.conversation=conversation_text\n",
    "                statement.type_of='A'\n",
    "                statement.source=source\n",
    "                statement.persona='bot:'+self.chatbot.name\n",
    "                statements_to_create.append(statement)\n",
    "        self.chatbot.storage.create_many(statements_to_create)\n",
    "        self.chatbot.docvector_tool.train(statements_to_create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from service.MatchSys.match_sys import MatchSys\n",
    "\n",
    "\n",
    "matchsys = MatchSys(name='Alice',model_path=r'D:\\Code\\MyLongTimeProject\\A\\model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qatrain = QATrainer(matchsys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "a = pd.read_csv(r'data1.txt',\n",
    "                sep=\"$\",\n",
    "                engine='python'\n",
    "                )\n",
    "a.head(5)\n",
    "a.to_csv(r'data1.csv',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'a':[1,2,3], 'b':[4,5,6], 'c':[7,8]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,k in enumerate(a.items()):\n",
    "    print(index)\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "map = {}\n",
    "# data = pd.read_excel(r'C:\\Users\\Administrator\\Documents\\GitHub\\QQ-Bot-And-Tool\\data\\FixedReply\\å‚²å¨‡ç³»äºŒæ¬¡å…ƒbotè¯åº“5åƒè¯V1.2.xlsx',header=None, sheet_name=0)\n",
    "data = pd.read_excel(r\"data\\FixedReply\\Test-1K.xlsx\",header=None, sheet_name=0)\n",
    "for index,row in data.iterrows():\n",
    "    row[0] = str(row[0]).strip()\n",
    "    row[1] = str(row[1]).strip()\n",
    "    if row[0] in map:\n",
    "        map[row[0]].append(row[1])\n",
    "    else:\n",
    "        map[row[0]] = [row[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_excel(r\"data\\FixedReply\\Test-1K.xlsx\",header=None, sheet_name=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "# set HNSW index parameters\n",
    "M = 64  # number of connections each vertex will have\n",
    "ef_search = 32  # depth of layers explored during search\n",
    "ef_construction = 64  # depth of layers explored during index construction\n",
    "\n",
    "# initialize index (d == 128)\n",
    "index = faiss.IndexHNSWFlat(768, M)\n",
    "# set efConstruction and efSearch parameters\n",
    "index.hnsw.efConstruction = ef_construction\n",
    "index.hnsw.efSearch = ef_search\n",
    "# add data to index\n",
    "sentence_embeddings = np.load(\"data/vec_data.npy\")\n",
    "sentence_embeddings = sentence_embeddings.astype(np.float32)\n",
    "index.add(sentence_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sentence_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "import time\n",
    "\n",
    "class FaissSearch(object):\n",
    "    def __init__(self,**kwargs):\n",
    "        \n",
    "        self.vector_model = SentenceTransformer('data/text2vec-base-chinese')\n",
    "        self.nlist = 50\n",
    "        self.hnsw_index = None\n",
    "        self.signal_file_size = 10000\n",
    "        self.data_d = 128\n",
    "    def get_ids(self,data_list):\n",
    "        ids = []\n",
    "        for index,value in enumerate(data_list):\n",
    "            ids.append(index)\n",
    "        # å°†å‘é‡å¤„ç†ç»“æœå­˜å‚¨\n",
    "        ids_file = \"data/Faiss/ids_data.npy\"\n",
    "        np.save(ids_file, np.array(ids))\n",
    "        file_size = os.path.getsize(ids_file)\n",
    "        print(\"%7.3f MB\" % (file_size/1024/1024))\n",
    "    def data_process_10w(self,**kwargs):\n",
    "        data_save_path = kwargs.get('data_save_path',\"data/Faiss/vector_data\") \n",
    "        sentences = kwargs.get('data_list',None)\n",
    "        # åŠ è½½æ¨¡å‹ï¼Œå°†æ•°æ®è¿›è¡Œå‘é‡åŒ–å¤„ç†\n",
    "        sentence_embeddings = self.vector_model.encode(sentences)\n",
    "        # å°†å‘é‡å¤„ç†ç»“æœå­˜å‚¨\n",
    "        n, d = sentence_embeddings.shape\n",
    "        sentence_embeddings_file_name = str(n)+\"-\"+str(d)+\"-\"+str(time.time())+\"-vec_data.npy\"\n",
    "        np.save(os.path.join(data_save_path,sentence_embeddings_file_name), sentence_embeddings)\n",
    "        file_size = os.path.getsize(os.path.join(data_save_path,sentence_embeddings_file_name))\n",
    "        print(sentence_embeddings_file_name + \" %7.3f MB\" % (file_size/1024/1024))\n",
    "    def data_process_2_vector(self,**kwargs):\n",
    "        data_save_path = kwargs.get('data_save_path',\"data/Faiss/vector_data\") \n",
    "        if not os.path.exists(data_save_path):\n",
    "            os.mkdir(data_save_path)\n",
    "        data_list = kwargs.get('data_list',None)\n",
    "        file_list = kwargs.get('file_list',None)\n",
    "        if data_list:\n",
    "            # åŠ è½½æ¨¡å‹ï¼Œå°†æ•°æ®è¿›è¡Œå‘é‡åŒ–å¤„ç†\n",
    "            sentences = data_list\n",
    "            if len(sentences) <= 100000:\n",
    "                self.data_process_10w(**kwargs)\n",
    "            else:\n",
    "                for i in range(0, len(sentences), 100000):\n",
    "                    kwargs['data_list'] = sentences[i: i + 100000]\n",
    "                    self.data_process_10w(**kwargs)\n",
    "\n",
    "        elif file_list:\n",
    "            \"\"\"\n",
    "\n",
    "            \"\"\"\n",
    "    def build_hnsw(self,vec_path='data/Faiss/vector_data'):\n",
    "        files = []\n",
    "        for file in os.listdir(vec_path):\n",
    "            if file.endswith('.npy'):\n",
    "                files.append(os.path.join(vec_path,file))\n",
    "\n",
    "        n,d = np.load(files[0]).shape\n",
    "        # # set HNSW index parameters\n",
    "        # M = 64  # number of connections each vertex will have è¶Šå¤§æœç´¢æ—¶é—´è¶Šé•¿\n",
    "        # ef_search = 32  # depth of layers explored during search è¶Šå¤§æœç´¢æ—¶é—´è¶Šé•¿\n",
    "        # ef_construction = 64  # depth of layers explored during index construction è¶Šå¤§æ„å»ºæ—¶é—´è¶Šé•¿\n",
    "\n",
    "        # initialize index (d == 128)\n",
    "        description = 'IDMap,HNSW32,Flat'\n",
    "        self.index = faiss.index_factory(d, description)\n",
    "        # self.hnsw_index = faiss.IndexHNSWFlat(d, M)\n",
    "        # # set efConstruction and efSearch parameters\n",
    "        # self.hnsw_index.hnsw.efConstruction = ef_construction\n",
    "        # self.hnsw_index.hnsw.efSearch = ef_search\n",
    "        # # self.hnsw_index = faiss.IndexIDMap2(self.hnsw_index)\n",
    "        \n",
    "        self.add_data(files)\n",
    "    def add_data(self,vec_path_list=None):\n",
    "        index_embeddings = 0\n",
    "        for file in vec_path_list:\n",
    "            sentence_embeddings = np.load(file)\n",
    "            sentence_embeddings = sentence_embeddings.astype(np.float32)\n",
    "            \n",
    "            self.index.add_with_ids(sentence_embeddings,ids)\n",
    "            print(file + \"è½½å…¥å®Œæ¯•ï¼Œæ•°æ®é‡\", len(sentence_embeddings))\n",
    "            \n",
    "    def search(self,sentences,topk=1):\n",
    "        if isinstance(sentences,list):\n",
    "            pass\n",
    "        else:\n",
    "            sentences = [sentences]\n",
    "        sentence_embeddings = self.vector_model.encode(sentences)\n",
    "        return self.hnsw_index.search(sentence_embeddings,topk), self.index.search(sentence_embeddings,topk)\n",
    "faissSearch = FaissSearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5856-768-1700813950.7410042-vec_data.npy  17.156 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_excel(r\"data\\FixedReply\\å‚²å¨‡ç³»äºŒæ¬¡å…ƒbotè¯åº“5åƒè¯V1.2.xlsx\",header=None, sheet_name=0)\n",
    "faissSearch.data_process_2_vector(data_list=data[0].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è½½å…¥å‘é‡æ•°æ®å®Œæ¯•ï¼Œæ•°æ®é‡ 5856\n"
     ]
    }
   ],
   "source": [
    "faissSearch.add_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5856-768-1700813950.7410042-vec_data.npyè½½å…¥å®Œæ¯•ï¼Œæ•°æ®é‡ 5856\n"
     ]
    }
   ],
   "source": [
    "faissSearch.build_hnsw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.write_index(faissSearch.hnsw_index,'data/Faiss/hnws.indx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "hnsw_index, index = faissSearch.search(['æˆ‘å–œæ¬¢ä½ '])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[2.5935717e-10]], dtype=float32), array([[52]], dtype=int64))\n",
      "(array([[2.5935717e-10]], dtype=float32), array([[53]], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(hnsw_index)\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½é¢„å¤„ç†æ•°æ®\n",
    "import numpy as np\n",
    "sentences = list(map.keys())\n",
    "sentence_embeddings = np.load(\"data/vec_data.npy\")\n",
    "print(\"è½½å…¥å‘é‡æ•°æ®å®Œæ¯•ï¼Œæ•°æ®é‡\", len(sentence_embeddings))\n",
    "\n",
    "# ä½¿ç”¨æ„å»ºå‘é‡æ—¶çš„æ¨¡å‹æ¥æ„å»ºå‘é‡ç´¢å¼•\n",
    "import faiss\n",
    "dimension = sentence_embeddings.shape[1]\n",
    "quantizer = faiss.IndexFlatL2(dimension)\n",
    "nlist = 50\n",
    "index = faiss.IndexIVFFlat(quantizer, dimension, nlist)\n",
    "index.train(sentence_embeddings)\n",
    "index.add(sentence_embeddings)\n",
    "print(\"å»ºç«‹å‘é‡ç´¢å¼•å®Œæ¯•ï¼Œæ•°æ®é‡\", index.ntotal)\n",
    "\n",
    "# å°è¯•è¿›è¡ŒæŸ¥è¯¢\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('data/text2vec-base-chinese')\n",
    "print(\"è½½å…¥æ¨¡å‹å®Œæ¯•\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topK = 10\n",
    "search = model.encode([\"å¥½ç´¯å•Š\"])\n",
    "D, I = index.search(search, topK)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3511, 100)\n",
      "3511\n"
     ]
    }
   ],
   "source": [
    "\n",
    "img = Image.open(r\"D:\\Data\\Image\\Normal\\Persion\\icoser.net (02).jpg\")\n",
    "\n",
    "gray_img = img.convert('L')\n",
    "img_array = np.array(gray_img)\n",
    "img_array = img_array / 255\n",
    "pca = PCA(n_components=100)\n",
    "transformed_vector = pca.fit_transform(img_array)\n",
    "pca2 = PCA(n_components=100)\n",
    "transformed_vector = pca2.fit_transform(transformed_vector)\n",
    "print(transformed_vector.shape)\n",
    "print(len(transformed_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "extracting feature from image No. 1 0486A7467002C3EA08331A7C02CCBA04.jpg, 12 images in total\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "extracting feature from image No. 2 1651812572141.jpg, 12 images in total\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "extracting feature from image No. 3 1651812581758.jpg, 12 images in total\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "extracting feature from image No. 4 32F31CDB9BA8C8F831F7D3BC1EC858E6.jpg, 12 images in total\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "extracting feature from image No. 5 75BE6EECCC48ACA7C2F07EE34B5A4888.jpg, 12 images in total\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "extracting feature from image No. 6 8DECDED8768C8D147C800E8DECDED8768C8D147C800E0C012313B88DECDED8768C8D147C800E0C012313B88DECDED8768C8D147C800E0C012313B88DECDED8768C8D147C800E0C012313B88DECDED8768C8D147C800E0C012313B88DECDED8768C8D147C800E0C012313B0C012313B8.jpg, 12 images in total\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "extracting feature from image No. 7 943EF2417F05FD1DF39FDAFE25B97096.jpg, 12 images in total\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "extracting feature from image No. 8 9A0C365782E081894D7473D7F77C727F.jpg, 12 images in total\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "extracting feature from image No. 9 AD14B02F0A65BECC3588EAF9650D8D03.jpg, 12 images in total\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "extracting feature from image No. 10 CB73CE0B8FF2E0E3638E9A8F600F3E6A.jpg, 12 images in total\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "extracting feature from image No. 11 F33F2F294E5F738A9D4E47B00EE6B57B.jpg, 12 images in total\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "extracting feature from image No. 12 mmm.jpg, 12 images in total\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import argparse\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input as preprocess_input_vgg\n",
    "from keras.utils import image_utils\n",
    "from numpy import linalg as LA\n",
    "import os\n",
    "import sys\n",
    "from os.path import dirname\n",
    "\n",
    "\n",
    "class VGGNet(object):\n",
    "    def __init__(self):\n",
    "        self.input_shape = (224, 224, 3)\n",
    "        self.weight = 'imagenet'\n",
    "        self.pooling = 'max'\n",
    "        self.model_vgg = VGG16(weights=self.weight,\n",
    "                               input_shape=(self.input_shape[0], self.input_shape[1], self.input_shape[2]),\n",
    "                               pooling=self.pooling,\n",
    "                               include_top=False)\n",
    "        self.model_vgg.predict(np.zeros((1, 224, 224, 3)))\n",
    "\n",
    "    def vgg_extract_feat(self, img_path):\n",
    "        img = image_utils.load_img(img_path, target_size=(self.input_shape[0], self.input_shape[1]))\n",
    "        img = image_utils.img_to_array(img)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        img = preprocess_input_vgg(img)\n",
    "        feat = self.model_vgg.predict(img)\n",
    "        norm_feat = feat[0] / LA.norm(feat[0])\n",
    "        norm_feat = [i.item() for i in norm_feat]\n",
    "        return norm_feat\n",
    "    \n",
    "def get_imlist(path):\n",
    "    return [os.path.join(path,f) for f in os.listdir(path) if f.endswith('.jpg')]\n",
    "\n",
    "\n",
    "img_lib_path = 'D:\\Data\\Image\\emoji'\n",
    "img_index_path = './data/faiss/img_index.h5'\n",
    "img_list = get_imlist(img_lib_path)\n",
    "feats = []\n",
    "names = []\n",
    "model = VGGNet()\n",
    "for i, img_path in enumerate(img_list):\n",
    "    norm_feat = model.vgg_extract_feat(img_path)\n",
    "    img_name = os.path.split(img_path)[1]\n",
    "    feats.append(norm_feat)\n",
    "    names.append(img_name)\n",
    "    print(\"extracting feature from image No. %d %s, %d images in total\" %((i+1), img_name ,len(img_list)))\n",
    "feats = np.array(feats)\n",
    "h5f = h5py.File(img_index_path, 'w')\n",
    "h5f.create_dataset('dataset_1', data = feats)\n",
    "h5f.create_dataset('dataset_2', data = np.string_(names))\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import argparse\n",
    "from service.vggnet import VGGNet\n",
    "from service.numpy_retrieval import NumpyRetrieval\n",
    "from service.faiss_retrieval import FaissRetrieval\n",
    "from service.es_retrieval import ESRetrieval\n",
    "from service.milvus_retrieval import MilvusRetrieval\n",
    "import os\n",
    "import sys\n",
    "from os.path import dirname\n",
    "BASE_DIR = dirname(os.path.abspath(__file__))\n",
    "sys.path.append(BASE_DIR)\n",
    "\n",
    "\n",
    "class RetrievalEngine(object):\n",
    "\n",
    "    def __init__(self, index_file, db_name):\n",
    "        self.index_file = index_file\n",
    "        self.db_name = db_name\n",
    "        self.numpy_r = self.faiss_r = self.es_r = self.milvus_r = None\n",
    "\n",
    "    def get_method(self, m_name):\n",
    "        m_name = \"%s_handler\" % str(m_name)\n",
    "        method = getattr(self, m_name, self.default_handler)\n",
    "        return method\n",
    "\n",
    "    def numpy_handler(self, query_vector, req_id=None):\n",
    "        # numpyè®¡ç®—\n",
    "        if self.numpy_r is None:\n",
    "            self.numpy_r = NumpyRetrieval(self.index_file)\n",
    "        return self.numpy_r.retrieve(query_vector)\n",
    "\n",
    "    def faiss_handler(self, query_vector, req_id=None):\n",
    "        # faissè®¡ç®—\n",
    "        if self.faiss_r is None:\n",
    "            self.faiss_r = FaissRetrieval(self.index_file)\n",
    "        return self.faiss_r.retrieve(query_vector)\n",
    "\n",
    "    def es_handler(self, query_vector, req_id=None):\n",
    "        # esè®¡ç®—\n",
    "        if self.es_r is None:\n",
    "            self.es_r = ESRetrieval(self.db_name, self.index_file)\n",
    "        return self.es_r.retrieve(query_vector)\n",
    "\n",
    "    def milvus_handler(self, query_vector, req_id=None):\n",
    "        # milvusè®¡ç®—\n",
    "        if self.milvus_r is None:\n",
    "            self.milvus_r = MilvusRetrieval(self.db_name, self.index_file)\n",
    "        return self.milvus_r.retrieve(query_vector)\n",
    "\n",
    "    def default_handler(self, query_vector, req_id=None):\n",
    "        return []\n",
    "\n",
    "\n",
    "query_img = \"D:\\Data\\Image\\emoji\\-29af59a4b1fcbc27.gif\"\n",
    "\n",
    "\n",
    "    parser.add_argument(\"--index_file\", type=str, default=os.path.join(BASE_DIR, 'index', 'train.h5'), help=\"index file path.\")\n",
    "    parser.add_argument(\"--db_name\", type=str, default='image_retrieval', help=\"database name.\")\n",
    "    parser.add_argument(\"--engine\", type=str, default='numpy', help=\"retrieval engine.\")\n",
    "    args = vars(parser.parse_args())\n",
    "# 1.å›¾ç‰‡æ¨ç†\n",
    "model = VGGNet()\n",
    "query_vector = model.vgg_extract_feat(query_img)\n",
    "# 2.å›¾ç‰‡æ£€ç´¢\n",
    "re = RetrievalEngine(img_index_path, args[\"db_name\"])\n",
    "result = re.get_method(args[\"engine\"])(query_vector, None)\n",
    "print(result)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
